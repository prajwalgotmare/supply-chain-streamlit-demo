{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the generated trip data...\n",
      "Data loaded successfully.\n",
      "\n",
      "Performing feature engineering (One-Hot Encoding)...\n",
      "Categorical features have been encoded.\n",
      "\n",
      "Defining features (X) and target (y)...\n",
      "Splitting data into training and testing sets (80/20 split)...\n",
      "Training set has 800 samples.\n",
      "Testing set has 200 samples.\n",
      "\n",
      "Training the RandomForestRegressor model...\n",
      "Model training complete.\n",
      "\n",
      "Evaluating the model on the unseen test set...\n",
      "\n",
      "--- Model Performance Metrics ---\n",
      "Mean Absolute Error (MAE): 0.63 hours\n",
      "  -> Interpretation: On average, our model's prediction is off by ±0.63 hours.\n",
      "Root Mean Squared Error (RMSE): 0.84 hours\n",
      "  -> Interpretation: Similar to MAE, but penalizes larger errors more heavily.\n",
      "R-squared (R²): 0.992\n",
      "  -> Interpretation: Our model explains 99.2% of the variance in the trip times.\n",
      "Mean Absolute Percentage Error (MAPE): 4.79%\n",
      "  -> Interpretation: On average, our model's prediction is off by 4.79%.\n",
      "---------------------------------\n",
      "\n",
      "Saving model and all performance assets to disk...\n",
      "- Model saved as 'eta_model.pkl'\n",
      "- Model assets (columns and metrics) saved as 'eta_model_assets.json'\n",
      "\n",
      "✅ All steps completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# --- Helper Function for MAPE ---\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    \"\"\"Calculates MAPE, handling cases where y_true is zero.\"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # Avoid division by zero\n",
    "    non_zero_mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[non_zero_mask] - y_pred[non_zero_mask]) / y_true[non_zero_mask])) * 100\n",
    "\n",
    "# --- 1. Load the Dataset ---\n",
    "print(\"Loading the generated trip data...\")\n",
    "try:\n",
    "    df = pd.read_csv('data/eta_trip_data.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'eta_trip_data.csv' not found. Please run the data generation script first.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Data loaded successfully.\")\n",
    "\n",
    "# --- 2. Feature Engineering & Preprocessing ---\n",
    "print(\"\\nPerforming feature engineering (One-Hot Encoding)...\")\n",
    "df_processed = pd.get_dummies(df, columns=['vehicle_type', 'weather', 'load_type'])\n",
    "print(\"Categorical features have been encoded.\")\n",
    "\n",
    "# --- 3. Define Features (X) and Target (y) ---\n",
    "print(\"\\nDefining features (X) and target (y)...\")\n",
    "y = df_processed['actual_eta_hours']\n",
    "X = df_processed.drop(columns=['actual_eta_hours', 'route_id'])\n",
    "model_columns = X.columns.tolist() # Save column order\n",
    "\n",
    "# --- 4. Split Data into Training and Testing Sets ---\n",
    "print(\"Splitting data into training and testing sets (80/20 split)...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"Training set has {len(X_train)} samples.\")\n",
    "print(f\"Testing set has {len(X_test)} samples.\")\n",
    "\n",
    "# --- 5. Train the Regression Model ---\n",
    "print(\"\\nTraining the RandomForestRegressor model...\")\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- 6. Evaluate the Model with Multiple Metrics ---\n",
    "print(\"\\nEvaluating the model on the unseen test set...\")\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse) # Take the square root of MSE to get RMSE\n",
    "r2 = r2_score(y_test, predictions)\n",
    "mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "\n",
    "# The 'confidence' for the final output is based on the MAE\n",
    "confidence_interval = round(mae, 2)\n",
    "\n",
    "print(\"\\n--- Model Performance Metrics ---\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f} hours\")\n",
    "print(f\"  -> Interpretation: On average, our model's prediction is off by ±{confidence_interval} hours.\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f} hours\")\n",
    "print(f\"  -> Interpretation: Similar to MAE, but penalizes larger errors more heavily.\")\n",
    "print(f\"R-squared (R²): {r2:.3f}\")\n",
    "print(f\"  -> Interpretation: Our model explains {r2:.1%} of the variance in the trip times.\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "print(f\"  -> Interpretation: On average, our model's prediction is off by {mape:.2f}%.\")\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "# --- 7. Save the Model and Supporting Assets ---\n",
    "print(\"\\nSaving model and all performance assets to disk...\")\n",
    "\n",
    "# a) Save the trained model object using pickle\n",
    "with open('eta_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "print(\"- Model saved as 'eta_model.pkl'\")\n",
    "\n",
    "# b) Save the list of feature columns and all calculated metrics\n",
    "asset_data = {\n",
    "    \"model_columns\": model_columns,\n",
    "    \"performance_metrics\": {\n",
    "        \"confidence_mae_hours\": confidence_interval,\n",
    "        \"rmse_hours\": round(rmse, 2),\n",
    "        \"r2_score\": round(r2, 3),\n",
    "        \"mape_percent\": round(mape, 2)\n",
    "    }\n",
    "}\n",
    "with open('eta_model_assets.json', 'w') as f:\n",
    "    json.dump(asset_data, f, indent=4)\n",
    "print(\"- Model assets (columns and metrics) saved as 'eta_model_assets.json'\")\n",
    "\n",
    "print(\"\\n✅ All steps completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
